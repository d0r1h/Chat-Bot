{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:47:34.082711Z","iopub.execute_input":"2022-06-26T03:47:34.084218Z","iopub.status.idle":"2022-06-26T03:47:34.090040Z","shell.execute_reply.started":"2022-06-26T03:47:34.084159Z","shell.execute_reply":"2022-06-26T03:47:34.088842Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"path = '../input/datas/messages.json'","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:47:34.124814Z","iopub.execute_input":"2022-06-26T03:47:34.125966Z","iopub.status.idle":"2022-06-26T03:47:34.130686Z","shell.execute_reply.started":"2022-06-26T03:47:34.125922Z","shell.execute_reply":"2022-06-26T03:47:34.129506Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"data = pd.read_json(path)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:47:34.171577Z","iopub.execute_input":"2022-06-26T03:47:34.172460Z","iopub.status.idle":"2022-06-26T03:47:50.531742Z","shell.execute_reply.started":"2022-06-26T03:47:34.172408Z","shell.execute_reply":"2022-06-26T03:47:50.530844Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"qq = []\naa = []\nfor k in range(3):\n    for i, j in enumerate(data['conversations'][k]['MessageList']):\n        s = ''\n        if data['conversations'][k]['MessageList'][i]['displayName'] != None:\n            a = data['conversations'][k]['MessageList'][i]['content']\n            s = s+a\n        qq.append(s)\n        s = ''\n        pass\n        if data['conversations'][k]['MessageList'][i]['displayName'] == None:\n            a = data['conversations'][k]['MessageList'][i]['content']\n            s = s+a\n\n        aa.append(s)\n        s = ''\n","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:47:50.534199Z","iopub.execute_input":"2022-06-26T03:47:50.534738Z","iopub.status.idle":"2022-06-26T03:47:50.550069Z","shell.execute_reply.started":"2022-06-26T03:47:50.534705Z","shell.execute_reply":"2022-06-26T03:47:50.548884Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"qq","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:47:50.551333Z","iopub.execute_input":"2022-06-26T03:47:50.551859Z","iopub.status.idle":"2022-06-26T03:47:50.571988Z","shell.execute_reply.started":"2022-06-26T03:47:50.551824Z","shell.execute_reply":"2022-06-26T03:47:50.570818Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"test_list=qq\nsize = len(test_list)\nidx_list = [idx for idx, val in\n            enumerate(test_list) if val == '']\n  \n  \nres = [test_list[i: j+1] for i, j in\n        zip([0] + idx_list, idx_list + \n        ([size] if idx_list[-1] != size else []))]\n  \nqqqq = [' '.join(i)  for i in res]","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:47:50.574253Z","iopub.execute_input":"2022-06-26T03:47:50.574950Z","iopub.status.idle":"2022-06-26T03:47:50.582406Z","shell.execute_reply.started":"2022-06-26T03:47:50.574913Z","shell.execute_reply":"2022-06-26T03:47:50.581528Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"test_list = aa\nsize = len(test_list)\nidx_list = [idx  for idx, val in\n            enumerate(test_list) if val == '']\n  \n  \nres = [test_list[i: j+1] for i, j in\n        zip([0] + idx_list, idx_list + \n        ([size] if idx_list[-1] != size else []))]\n  \naaaa = [' '.join(i)  for i in res]","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:47:50.583584Z","iopub.execute_input":"2022-06-26T03:47:50.584279Z","iopub.status.idle":"2022-06-26T03:47:50.594978Z","shell.execute_reply.started":"2022-06-26T03:47:50.584228Z","shell.execute_reply":"2022-06-26T03:47:50.593889Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"len([i for i in qqqq if i])","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:47:50.596670Z","iopub.execute_input":"2022-06-26T03:47:50.597722Z","iopub.status.idle":"2022-06-26T03:47:50.608427Z","shell.execute_reply.started":"2022-06-26T03:47:50.597678Z","shell.execute_reply":"2022-06-26T03:47:50.607179Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"len([i for i in aaaa if i])","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:47:50.610237Z","iopub.execute_input":"2022-06-26T03:47:50.610636Z","iopub.status.idle":"2022-06-26T03:47:50.622900Z","shell.execute_reply.started":"2022-06-26T03:47:50.610600Z","shell.execute_reply":"2022-06-26T03:47:50.621631Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"ans = [i    for i in aaaa   if i != ' ']","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:47:50.625345Z","iopub.execute_input":"2022-06-26T03:47:50.626245Z","iopub.status.idle":"2022-06-26T03:47:50.632081Z","shell.execute_reply.started":"2022-06-26T03:47:50.626192Z","shell.execute_reply":"2022-06-26T03:47:50.631153Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"ans.reverse()\nque = [i    for i in qqqq   if i != ' ']\nque.reverse()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:47:50.633466Z","iopub.execute_input":"2022-06-26T03:47:50.633989Z","iopub.status.idle":"2022-06-26T03:47:50.645135Z","shell.execute_reply.started":"2022-06-26T03:47:50.633957Z","shell.execute_reply":"2022-06-26T03:47:50.643716Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"ans","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:47:50.648767Z","iopub.execute_input":"2022-06-26T03:47:50.649155Z","iopub.status.idle":"2022-06-26T03:47:50.658566Z","shell.execute_reply.started":"2022-06-26T03:47:50.649122Z","shell.execute_reply":"2022-06-26T03:47:50.657446Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"ss = pd.DataFrame(zip(que, ans))","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:47:50.659906Z","iopub.execute_input":"2022-06-26T03:47:50.660306Z","iopub.status.idle":"2022-06-26T03:47:50.669686Z","shell.execute_reply.started":"2022-06-26T03:47:50.660250Z","shell.execute_reply":"2022-06-26T03:47:50.668345Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"import re","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:47:50.671113Z","iopub.execute_input":"2022-06-26T03:47:50.672791Z","iopub.status.idle":"2022-06-26T03:47:50.679601Z","shell.execute_reply.started":"2022-06-26T03:47:50.672749Z","shell.execute_reply":"2022-06-26T03:47:50.678566Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"def cleanhtml(raw_html):\n  cleanr = re.compile(r'<[^>]+>')\n  cleantext = re.sub(cleanr, '', raw_html)\n  cleantext = re.sub(r'http\\S+', '', cleantext)\n\n  return cleantext","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:47:50.680870Z","iopub.execute_input":"2022-06-26T03:47:50.681397Z","iopub.status.idle":"2022-06-26T03:47:50.691720Z","shell.execute_reply.started":"2022-06-26T03:47:50.681363Z","shell.execute_reply":"2022-06-26T03:47:50.690678Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"cleanhtml(ss[0][8])","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:47:50.693128Z","iopub.execute_input":"2022-06-26T03:47:50.693488Z","iopub.status.idle":"2022-06-26T03:47:50.708221Z","shell.execute_reply.started":"2022-06-26T03:47:50.693455Z","shell.execute_reply":"2022-06-26T03:47:50.707399Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ss[0]=ss[0].map(lambda x : cleanhtml(x))\nss[1]=ss[1].map(lambda x : cleanhtml(x))","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:47:50.709344Z","iopub.execute_input":"2022-06-26T03:47:50.710468Z","iopub.status.idle":"2022-06-26T03:47:50.720605Z","shell.execute_reply.started":"2022-06-26T03:47:50.710429Z","shell.execute_reply":"2022-06-26T03:47:50.718992Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"ss","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:47:50.722830Z","iopub.execute_input":"2022-06-26T03:47:50.723966Z","iopub.status.idle":"2022-06-26T03:47:50.738583Z","shell.execute_reply.started":"2022-06-26T03:47:50.723909Z","shell.execute_reply":"2022-06-26T03:47:50.737367Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"qstn=ss[0]\n\nanwr=ss[1]\n\npair=list(zip(qstn,anwr))","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:47:50.740573Z","iopub.execute_input":"2022-06-26T03:47:50.741445Z","iopub.status.idle":"2022-06-26T03:47:50.747762Z","shell.execute_reply.started":"2022-06-26T03:47:50.741393Z","shell.execute_reply":"2022-06-26T03:47:50.746874Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"import numpy as np","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:47:50.748878Z","iopub.execute_input":"2022-06-26T03:47:50.749707Z","iopub.status.idle":"2022-06-26T03:47:50.759849Z","shell.execute_reply.started":"2022-06-26T03:47:50.749672Z","shell.execute_reply":"2022-06-26T03:47:50.759022Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"input_docs = []\ntarget_docs = []\ninput_tokens = set()\ntarget_tokens = set()\nfor line in pair:\n  input_doc, target_doc = line[0], line[1]\n  # Appending each input sentence to input_docs\n  input_docs.append(input_doc)\n  # Splitting words from punctuation  \n  target_doc = \" \".join(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc))\n  # Redefine target_doc below and append it to target_docs\n  target_doc = '<START> ' + target_doc + ' <END>'\n  target_docs.append(target_doc)\n  \n  # Now we split up each sentence into words and add each unique word to our vocabulary set\n  for token in re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc):\n    if token not in input_tokens:\n      input_tokens.add(token)\n  for token in target_doc.split():\n    if token not in target_tokens:\n      target_tokens.add(token)\ninput_tokens = sorted(list(input_tokens))\ntarget_tokens = sorted(list(target_tokens))\nnum_encoder_tokens = len(input_tokens)\nnum_decoder_tokens = len(target_tokens)\n\ninput_features_dict = dict(\n    [(token, i) for i, token in enumerate(input_tokens)])\ntarget_features_dict = dict(\n    [(token, i) for i, token in enumerate(target_tokens)])\n\nreverse_input_features_dict = dict(\n    (i, token) for token, i in input_features_dict.items())\nreverse_target_features_dict = dict(\n    (i, token) for token, i in target_features_dict.items())\nmax_encoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)) for input_doc in input_docs])\nmax_decoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc)) for target_doc in target_docs])\n\nencoder_input_data = np.zeros(\n    (len(input_docs), max_encoder_seq_length, num_encoder_tokens),\n    dtype='float32')\ndecoder_input_data = np.zeros(\n    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n    dtype='float32')\ndecoder_target_data = np.zeros(\n    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n    dtype='float32')\n\nfor line, (input_doc, target_doc) in enumerate(zip(input_docs, target_docs)):\n    for timestep, token in enumerate(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)):\n        #Assign 1. for the current line, timestep, & word in encoder_input_data\n        encoder_input_data[line, timestep, input_features_dict[token]] = 1.\n    \n    for timestep, token in enumerate(target_doc.split()):\n        decoder_input_data[line, timestep, target_features_dict[token]] = 1.\n        if timestep > 0:\n            decoder_target_data[line, timestep - 1, target_features_dict[token]] = 1.","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:47:50.761054Z","iopub.execute_input":"2022-06-26T03:47:50.761568Z","iopub.status.idle":"2022-06-26T03:47:50.798759Z","shell.execute_reply.started":"2022-06-26T03:47:50.761536Z","shell.execute_reply":"2022-06-26T03:47:50.797556Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nfrom keras.layers import Input, LSTM, Dense\nfrom keras.models import Model\n#Dimensionality\ndimensionality = 128\n#The batch size and number of epochs\nbatch_size = 64\nepochs = 20\n#Encoder\nencoder_inputs = Input(shape=(None, num_encoder_tokens))\nencoder_lstm = LSTM(dimensionality, return_state=True)\nencoder_outputs, state_hidden, state_cell = encoder_lstm(encoder_inputs)\nencoder_states = [state_hidden, state_cell]\n#Decoder\ndecoder_inputs = Input(shape=(None, num_decoder_tokens))\ndecoder_lstm = LSTM(dimensionality, return_sequences=True, return_state=True)\ndecoder_outputs, decoder_state_hidden, decoder_state_cell = decoder_lstm(decoder_inputs, initial_state=encoder_states)\ndecoder_dense = Dense(num_decoder_tokens, activation='softmax')\ndecoder_outputs = decoder_dense(decoder_outputs)\n\n\ntraining_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n#Compiling\ntraining_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'], sample_weight_mode='temporal')\n#Training\ntraining_model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size = batch_size, epochs = epochs, validation_split = 0.2)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:47:50.800583Z","iopub.execute_input":"2022-06-26T03:47:50.801181Z","iopub.status.idle":"2022-06-26T03:48:30.587116Z","shell.execute_reply.started":"2022-06-26T03:47:50.801147Z","shell.execute_reply":"2022-06-26T03:48:30.585604Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"training_model.save('training_model1.h5')","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:48:30.589538Z","iopub.execute_input":"2022-06-26T03:48:30.590023Z","iopub.status.idle":"2022-06-26T03:48:30.665935Z","shell.execute_reply.started":"2022-06-26T03:48:30.589974Z","shell.execute_reply":"2022-06-26T03:48:30.664895Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"encoder_inputs = training_model.input[0]\nencoder_outputs, state_h_enc, state_c_enc = training_model.layers[2].output\nencoder_states = [state_h_enc, state_c_enc]\nencoder_model = Model(encoder_inputs, encoder_states)\n\nlatent_dim = 128\ndecoder_state_input_hidden = Input(shape=(latent_dim,))\ndecoder_state_input_cell = Input(shape=(latent_dim,))\ndecoder_states_inputs = [decoder_state_input_hidden, decoder_state_input_cell]\ndecoder_outputs, state_hidden, state_cell = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\ndecoder_states = [state_hidden, state_cell]\ndecoder_outputs = decoder_dense(decoder_outputs)\ndecoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:48:30.667511Z","iopub.execute_input":"2022-06-26T03:48:30.667882Z","iopub.status.idle":"2022-06-26T03:48:30.930495Z","shell.execute_reply.started":"2022-06-26T03:48:30.667848Z","shell.execute_reply":"2022-06-26T03:48:30.929319Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"def decode_response(test_input):\n    #Getting the output states to pass into the decoder\n    states_value = encoder_model.predict(test_input)\n    #Generating empty target sequence of length 1\n    target_seq = np.zeros((1, 1, num_decoder_tokens))\n    #Setting the first token of target sequence with the start token\n    target_seq[0, 0, target_features_dict['<START>']] = 1.\n    \n    #A variable to store our response word by word\n    decoded_sentence = ''\n    \n    stop_condition = False\n    while not stop_condition:\n      #Predicting output tokens with probabilities and states\n      output_tokens, hidden_state, cell_state = decoder_model.predict([target_seq] + states_value)\n#Choosing the one with highest probability\n      sampled_token_index = np.argmax(output_tokens[0, -1, :])\n      sampled_token = reverse_target_features_dict[sampled_token_index]\n      decoded_sentence += \" \" + sampled_token\n#Stop if hit max length or found the stop token\n      if (sampled_token == '<END>' or len(decoded_sentence) > max_decoder_seq_length):\n        stop_condition = True\n#Update the target sequence\n      target_seq = np.zeros((1, 1, num_decoder_tokens))\n      target_seq[0, 0, sampled_token_index] = 1.\n      #Update states\n      states_value = [hidden_state, cell_state]\n    return decoded_sentence\n","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:48:30.932654Z","iopub.execute_input":"2022-06-26T03:48:30.933167Z","iopub.status.idle":"2022-06-26T03:48:30.943628Z","shell.execute_reply.started":"2022-06-26T03:48:30.933118Z","shell.execute_reply":"2022-06-26T03:48:30.942160Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"def string_to_matrix(user_input):\n    tokens = re.findall(r\"[\\w']+|[^\\s\\w]\", user_input)\n    user_input_matrix = np.zeros(\n      (1, max_encoder_seq_length, num_encoder_tokens),\n      dtype='float32')\n    for timestep, token in enumerate(tokens):\n      if token in input_features_dict:\n        user_input_matrix[0, timestep, input_features_dict[token]] = 1.\n    return user_input_matrix","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:48:30.945976Z","iopub.execute_input":"2022-06-26T03:48:30.946489Z","iopub.status.idle":"2022-06-26T03:48:30.954220Z","shell.execute_reply.started":"2022-06-26T03:48:30.946440Z","shell.execute_reply":"2022-06-26T03:48:30.953365Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"def generate_response(user_input):\n    input_matrix = string_to_matrix(user_input)\n    chatbot_response = decode_response(input_matrix)\n    #Remove <START> and <END> tokens from chatbot_response\n    chatbot_response = chatbot_response.replace(\"<START>\",'')\n    chatbot_response = chatbot_response.replace(\"<END>\",'')\n    return chatbot_response","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:48:30.956053Z","iopub.execute_input":"2022-06-26T03:48:30.956472Z","iopub.status.idle":"2022-06-26T03:48:30.970620Z","shell.execute_reply.started":"2022-06-26T03:48:30.956439Z","shell.execute_reply":"2022-06-26T03:48:30.969104Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"generate_response('Hi')","metadata":{"execution":{"iopub.status.busy":"2022-06-26T03:48:30.973307Z","iopub.execute_input":"2022-06-26T03:48:30.973917Z","iopub.status.idle":"2022-06-26T03:48:32.147511Z","shell.execute_reply.started":"2022-06-26T03:48:30.973865Z","shell.execute_reply":"2022-06-26T03:48:32.146372Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}